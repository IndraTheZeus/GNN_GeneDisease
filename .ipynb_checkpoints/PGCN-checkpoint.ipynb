{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca77e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : GNNGeneDisease\n",
      "    active env location : /home/indradutta/miniconda3/envs/GNNGeneDisease\n",
      "            shell level : 2\n",
      "       user config file : /home/indradutta/.condarc\n",
      " populated config files : \n",
      "          conda version : 23.9.0\n",
      "    conda-build version : not installed\n",
      "         python version : 3.11.4.final.0\n",
      "       virtual packages : __archspec=1=x86_64\n",
      "                          __cuda=12.0=0\n",
      "                          __glibc=2.35=0\n",
      "                          __linux=6.2.0=0\n",
      "                          __unix=0=0\n",
      "       base environment : /home/indradutta/miniconda3  (writable)\n",
      "      conda av data dir : /home/indradutta/miniconda3/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "          package cache : /home/indradutta/miniconda3/pkgs\n",
      "                          /home/indradutta/.conda/pkgs\n",
      "       envs directories : /home/indradutta/miniconda3/envs\n",
      "                          /home/indradutta/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/23.9.0 requests/2.31.0 CPython/3.11.4 Linux/6.2.0-36-generic ubuntu/22.04.2 glibc/2.35\n",
      "                UID:GID : 1119:1128\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n",
      "Disease_gene_prioritization_GCN  PGCN.ipynb  README.md\n"
     ]
    }
   ],
   "source": [
    "!conda info #Working Environment is GNNGeneDisease\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890bb3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:35:14.643984: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-18 15:35:14.644033: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-18 15:35:14.644066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as sio\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ce2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 15:35:17.726544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 15:35:17.732487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-18 15:35:17.732712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "924ddd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5e92f",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6043fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD Disease Gene Adjacency Network\n",
    "gene_phenes_path = './Disease_gene_prioritization_GCN/data_prioritization/genes_phenes.mat'\n",
    "f = h5py.File(gene_phenes_path, 'r')\n",
    "gene_network_adj = sp.csc_matrix((np.array(f['GeneGene_Hs']['data']),\n",
    "    np.array(f['GeneGene_Hs']['ir']), np.array(f['GeneGene_Hs']['jc'])),\n",
    "    shape=(12331,12331))\n",
    "gene_network_adj = gene_network_adj.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24594e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 12331)\n",
      "[0.20273609 0.20273924 0.20274388 ... 2.12116944 2.12733221 2.12842815]\n"
     ]
    }
   ],
   "source": [
    "print(gene_network_adj.shape)\n",
    "print(np.unique(gene_network_adj.tocoo().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae15f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875c7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_edge_threshold(network_adj, threshold):\n",
    "    edge_tmp, edge_value, shape_tmp = sparse_to_tuple(network_adj)\n",
    "    preserved_edge_index = np.where(edge_value>threshold)[0]\n",
    "    preserved_network = sp.csr_matrix(\n",
    "        (edge_value[preserved_edge_index], \n",
    "        (edge_tmp[preserved_edge_index,0], edge_tmp[preserved_edge_index, 1])),\n",
    "        shape=shape_tmp)\n",
    "    return preserved_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc999264",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_network_adj = sp.csc_matrix((np.array(f['PhenotypeSimilarities']['data']),\n",
    "    np.array(f['PhenotypeSimilarities']['ir']), np.array(f['PhenotypeSimilarities']['jc'])),\n",
    "    shape=(3215, 3215))\n",
    "disease_network_adj = disease_network_adj.tocsr()  ## CONVERTED TO SPARSE ROW\n",
    "# >0.2 values get preserved\n",
    "disease_network_adj = network_edge_threshold(disease_network_adj, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7dc1911",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.200001 0.200002 0.200003 ... 0.999965 0.999998 1.      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3215x3215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 645965 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(disease_network_adj.tocoo().data))\n",
    "disease_network_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a032a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Gene Disease Adj is 1, 0 matrix, while gene_gene (12331, 12331)\n",
    "##        and disease-disease ( 3215, 3215) have edge level values\n",
    "\n",
    "dg_ref = f['GenePhene'][0][0]\n",
    "gene_disease_adj = sp.csc_matrix((np.array(f[dg_ref]['data']),\n",
    "    np.array(f[dg_ref]['ir']), np.array(f[dg_ref]['jc'])),\n",
    "    shape=(12331, 3215))\n",
    "gene_disease_adj = gene_disease_adj.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e7d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"data\": shape (3954,), type \"<f8\">"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[dg_ref]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e08c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 3215)\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "print(gene_disease_adj.shape)\n",
    "print(np.unique(gene_disease_adj.tocoo().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1fe014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WHAT DATA is THIS ? 34 novel associtaions of value 1, 0\n",
    "novel_associations_adj = sp.csc_matrix((np.array(f['NovelAssociations']['data']),\n",
    "    np.array(f['NovelAssociations']['ir']), np.array(f['NovelAssociations']['jc'])),\n",
    "    shape=(12331,3215))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab85a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"data\": shape (34,), type \"<f8\">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['NovelAssociations']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7977cb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 3215)\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "print(novel_associations_adj.shape)\n",
    "print(np.unique(novel_associations_adj.tocoo().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9faec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature value of each Gene: 4536 features per gene\n",
    "gene_feature_path = './Disease_gene_prioritization_GCN/data_prioritization/GeneFeatures.mat'\n",
    "f_gene_feature = h5py.File(gene_feature_path,'r')\n",
    "gene_feature_exp = np.array(f_gene_feature['GeneFeatures'])\n",
    "gene_feature_exp = np.transpose(gene_feature_exp)\n",
    "gene_network_exp = sp.csc_matrix(gene_feature_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "587eab04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 4536)\n",
      "[-2.5184551  -2.46199675 -2.46052243 ...  6.37752569  6.56798025\n",
      "  6.62628665]\n"
     ]
    }
   ],
   "source": [
    "print(gene_network_exp.shape)\n",
    "print(np.unique(gene_network_exp.tocoo().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de76070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"GenePhene\": shape (9, 1), type \"|O\">"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(f[dg_ref]['data'])\n",
    "f['GenePhene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d2cfb7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 1137)\n",
      "[2.28832952e-03 2.50000000e-02 3.57142857e-02 4.00000000e-02\n",
      " 4.34782609e-02 5.00000000e-02 5.26315789e-02 6.25000000e-02\n",
      " 6.66666667e-02 7.14285714e-02 7.69230769e-02 8.33333333e-02\n",
      " 8.69565217e-02 9.09090909e-02 1.00000000e-01 1.11111111e-01\n",
      " 1.17647059e-01 1.25000000e-01 1.30434783e-01 1.42857143e-01\n",
      " 1.53846154e-01 1.66666667e-01 1.73913043e-01 1.81818182e-01\n",
      " 1.87500000e-01 2.00000000e-01 2.14285714e-01 2.17391304e-01\n",
      " 2.22222222e-01 2.30769231e-01 2.50000000e-01 2.85714286e-01\n",
      " 3.00000000e-01 3.33333333e-01 3.63636364e-01 3.75000000e-01\n",
      " 3.84615385e-01 4.00000000e-01 4.44444444e-01 5.00000000e-01\n",
      " 5.71428571e-01 6.00000000e-01 6.66666667e-01 7.50000000e-01\n",
      " 8.00000000e-01 8.33333333e-01 1.00000000e+00 1.16666667e+00\n",
      " 1.28571429e+00 1.33333333e+00 1.50000000e+00 1.66666667e+00\n",
      " 1.72727273e+00 1.75000000e+00 2.00000000e+00 2.16666667e+00\n",
      " 2.25000000e+00 2.33333333e+00 2.50000000e+00 2.66666667e+00\n",
      " 3.00000000e+00 3.50000000e+00 4.00000000e+00 4.33333333e+00\n",
      " 5.00000000e+00 6.00000000e+00 7.00000000e+00 8.00000000e+00\n",
      " 9.00000000e+00 1.00000000e+01 1.10000000e+01 1.20000000e+01\n",
      " 1.30000000e+01 1.40000000e+01 1.90000000e+01 2.00000000e+01]\n",
      "(12331, 744)\n",
      "[0.02941176 0.04761905 0.05       0.05263158 0.05555556 0.0625\n",
      " 0.07142857 0.09090909 0.1        0.11111111 0.125      0.14285714\n",
      " 0.15384615 0.16666667 0.18181818 0.2        0.21052632 0.21428571\n",
      " 0.23076923 0.25       0.26315789 0.27777778 0.28571429 0.31578947\n",
      " 0.33333333 0.35714286 0.4        0.42857143 0.47368421 0.5\n",
      " 0.52631579 0.55555556 0.57142857 0.6        0.64285714 0.66666667\n",
      " 0.71428571 0.72222222 0.75       0.78571429 0.84210526 0.88888889\n",
      " 0.89473684 1.         1.07142857 1.14285714 1.33333333 1.5\n",
      " 2.         3.         4.        ]\n",
      "(12331, 2503)\n",
      "[0.00746269 0.05263158 0.08333333 0.09090909 0.1        0.11111111\n",
      " 0.125      0.14285714 0.15       0.16666667 0.2        0.25\n",
      " 0.28571429 0.33333333 0.4        0.5        0.66666667 1.\n",
      " 1.5        2.         3.        ]\n",
      "(12331, 1143)\n",
      "[0.08333333 0.13333333 0.14285714 0.2        0.25       0.33333333\n",
      " 0.5        0.66666667 1.         2.         3.        ]\n",
      "(12331, 324)\n",
      "[0.03571429 0.0625     0.09090909 0.1        0.11111111 0.125\n",
      " 0.14285714 0.16666667 0.1875     0.2        0.25       0.28571429\n",
      " 0.3125     0.33333333 0.375      0.4        0.5        0.6\n",
      " 0.66666667 0.8        1.         1.2        1.33333333 1.5\n",
      " 1.66666667 2.         3.         4.        ]\n",
      "(12331, 1188)\n",
      "[0.33333333 0.5        1.         2.        ]\n",
      "(12331, 4662)\n",
      "[0.09090909 0.125      0.14285714 0.2        0.22222222 0.25\n",
      " 0.33333333 0.5        0.66666667 1.         2.         3.        ]\n",
      "(12331, 1243)\n",
      "[2.12314225e-03 4.54545455e-02 5.00000000e-02 5.26315789e-02\n",
      " 5.55555556e-02 5.88235294e-02 6.66666667e-02 7.14285714e-02\n",
      " 7.69230769e-02 8.33333333e-02 9.09090909e-02 1.00000000e-01\n",
      " 1.11111111e-01 1.25000000e-01 1.42857143e-01 1.66666667e-01\n",
      " 1.81818182e-01 2.00000000e-01 2.50000000e-01 2.85714286e-01\n",
      " 3.33333333e-01 4.00000000e-01 4.28571429e-01 5.00000000e-01\n",
      " 5.71428571e-01 6.66666667e-01 1.00000000e+00 1.50000000e+00\n",
      " 2.00000000e+00 2.50000000e+00 3.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# // TODO: Explore why 1 - 9 and not 0 - 9\n",
    "## NOTE THIS DATA is different from gene_disease_adj  \n",
    "\n",
    "row_list = [3215, 1137, 744, 2503, 1143, 324, 1188, 4662, 1243]\n",
    "gene_feature_list_other_spe = list()\n",
    "for i in range(1,9):\n",
    "    dg_ref = f['GenePhene'][i][0]\n",
    "    disease_gene_adj_tmp = sp.csc_matrix((np.array(f[dg_ref]['data']),\n",
    "        np.array(f[dg_ref]['ir']), np.array(f[dg_ref]['jc'])),\n",
    "        shape=(12331, row_list[i]))\n",
    "    print(disease_gene_adj_tmp.shape)\n",
    "    print(np.unique(disease_gene_adj_tmp.tocoo().data))\n",
    "    gene_feature_list_other_spe.append(disease_gene_adj_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ec1458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<12331x1137 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 12010 stored elements in Compressed Sparse Column format>,\n",
       " <12331x744 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 30519 stored elements in Compressed Sparse Column format>,\n",
       " <12331x2503 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 68525 stored elements in Compressed Sparse Column format>,\n",
       " <12331x1143 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 4500 stored elements in Compressed Sparse Column format>,\n",
       " <12331x324 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 72846 stored elements in Compressed Sparse Column format>,\n",
       " <12331x1188 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 22150 stored elements in Compressed Sparse Column format>,\n",
       " <12331x4662 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 75199 stored elements in Compressed Sparse Column format>,\n",
       " <12331x1243 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 73284 stored elements in Compressed Sparse Column format>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gene_feature_list_other_spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26646523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3215, 16592)\n",
      "[2.05421771e-04 2.72671021e-04 2.87821641e-04 ... 9.20864777e-01\n",
      " 9.26488623e-01 9.86390140e-01]\n"
     ]
    }
   ],
   "source": [
    "disease_tfidf_path = './Disease_gene_prioritization_GCN/data_prioritization/clinicalfeatures_tfidf.mat'\n",
    "f_disease_tfidf = h5py.File(disease_tfidf_path)\n",
    "disease_tfidf = np.array(f_disease_tfidf['F'])\n",
    "disease_tfidf = np.transpose(disease_tfidf)\n",
    "disease_tfidf = sp.csc_matrix(disease_tfidf)\n",
    "print(disease_tfidf.shape)\n",
    "print(np.unique(disease_tfidf.tocoo().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67482211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<3215x3215 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 645965 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "dis_dis_adj_list= list()\n",
    "dis_dis_adj_list.append(disease_network_adj)\n",
    "print(dis_dis_adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6657a5",
   "metadata": {},
   "source": [
    "# DATA PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b13a917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[68.92149565  9.07395628 13.86730759 ...  0.          0.\n",
      "   0.        ]]\n",
      "(1, 12331)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12331,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_test_size = 0.1\n",
    "n_genes = 12331\n",
    "n_dis = 3215\n",
    "n_dis_rel_types = len(dis_dis_adj_list)\n",
    "print(n_dis_rel_types)\n",
    "gene_adj = gene_network_adj\n",
    "gene_degrees = np.array(gene_adj.sum(axis=0)).squeeze()\n",
    "print(gene_adj.sum(axis=0))\n",
    "print(gene_adj.sum(axis=0).shape)\n",
    "gene_degrees.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c75d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 3215)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3215,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_dis_adj = gene_disease_adj\n",
    "print(gene_dis_adj.shape)\n",
    "dis_gene_adj = gene_dis_adj.transpose(copy=True)\n",
    "dis_degrees_list = [np.array(dis_adj.sum(axis=0)).squeeze() for dis_adj in dis_dis_adj_list]\n",
    "dis_degrees_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96af076f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [array([68.92149565,  9.07395628, 13.86730759, ...,  0.        ,\n",
      "        0.        ,  0.        ]), array([68.92149565,  9.07395628, 13.86730759, ...,  0.        ,\n",
      "        0.        ,  0.        ])], 1: [array([ 1.      ,  1.      , 91.266734, ...,  7.260462,  1.      ,\n",
      "        1.      ]), array([ 1.      ,  1.      , 91.266734, ...,  7.260462,  1.      ,\n",
      "        1.      ])]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0,\n",
       "  0): [<12331x12331 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 733836 stored elements in Compressed Sparse Row format>, <12331x12331 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 733836 stored elements in Compressed Sparse Column format>],\n",
       " (0,\n",
       "  1): [<12331x3215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 3954 stored elements in Compressed Sparse Row format>],\n",
       " (1,\n",
       "  0): [<3215x12331 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 3954 stored elements in Compressed Sparse Column format>],\n",
       " (1,\n",
       "  1): [<3215x3215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 645965 stored elements in Compressed Sparse Row format>,\n",
       "  <3215x3215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "  \twith 645965 stored elements in Compressed Sparse Column format>]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [gene_adj, gene_adj.transpose(copy=True)],\n",
    "    (0, 1): [gene_dis_adj],\n",
    "    (1, 0): [dis_gene_adj],\n",
    "    (1, 1): dis_dis_adj_list + [x.transpose(copy=True) for x in dis_dis_adj_list],\n",
    "}\n",
    "degrees = {\n",
    "    0: [gene_degrees, gene_degrees],\n",
    "    1: dis_degrees_list + dis_degrees_list,\n",
    "}\n",
    "print(degrees)\n",
    "adj_mats_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "000198df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12331, 17480)\n",
      "(3215, 16592)\n"
     ]
    }
   ],
   "source": [
    "# Gene Feature Exp - Feature vector  + other 8 species\n",
    "gene_feat = sp.hstack(gene_feature_list_other_spe+[gene_feature_exp])\n",
    "print(gene_feat.shape)\n",
    "gene_nonzero_feat, gene_num_feat = gene_feat.shape\n",
    "gene_feat = sparse_to_tuple(gene_feat.tocoo())\n",
    "\n",
    "dis_feat = disease_tfidf\n",
    "dis_nonzero_feat, dis_num_feat = dis_feat.shape\n",
    "print(dis_feat.shape)\n",
    "dis_feat = sparse_to_tuple(dis_feat.tocoo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5265eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 17480, 1: 16592}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 12331, 1: 3215}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: dis_num_feat,\n",
    "}\n",
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: dis_nonzero_feat,\n",
    "}\n",
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: dis_feat,\n",
    "}\n",
    "print(num_feat)\n",
    "nonzero_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "933d2589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 6\n",
      "{(0, 0): 2, (0, 1): 1, (1, 0): 1, (1, 1): 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0, 0): [(12331, 12331), (12331, 12331)],\n",
       " (0, 1): [(12331, 3215)],\n",
       " (1, 0): [(3215, 12331)],\n",
       " (1, 1): [(3215, 3215), (3215, 3215)]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "# edge_type2decoder = {\n",
    "#     (0, 0): 'bilinear',\n",
    "#     (0, 1): 'bilinear',\n",
    "#     (1, 0): 'bilinear',\n",
    "#     (1, 1): 'bilinear',\n",
    "# }\n",
    "\n",
    "edge_type2decoder = {\n",
    "    (0, 0): 'innerproduct',\n",
    "    (0, 1): 'innerproduct',\n",
    "    (1, 0): 'innerproduct',\n",
    "    (1, 1): 'innerproduct',\n",
    "}\n",
    "\n",
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "num_edge_types = sum(edge_types.values())\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)\n",
    "\n",
    "print(edge_types)\n",
    "edge_type2dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc5c07",
   "metadata": {},
   "source": [
    "# INSIDE MAIN CALLING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72b24282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "del_all_flags(tf.compat.v1.app.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603abbc6",
   "metadata": {},
   "source": [
    "# FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fc5a7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_sample_size =  1  #Negative sample size\n",
    "learning_rate =  0.001 # 'Initial learning rate\n",
    "hidden1_units =  64 #'Number of units in hidden layer 1\n",
    "hidden2_units = 32 #Number of units in hidden layer 2\n",
    "weight_decay =  0.001  #Weight for L2 loss on embedding matrix\n",
    "dropout = 0.1 # Dropout rate (1 - keep probability)\n",
    "max_margin =  0.1 #Max margin parameter in hinge loss\n",
    "batch_size = 512\n",
    "bias = True #Bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc39102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.compat.v1.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.compat.v1.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.compat.v1.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.compat.v1.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.compat.v1.placeholder(tf.int32),\n",
    "        'dropout': tf.compat.v1.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.compat.v1.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.compat.v1.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5678f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=Tensor(\"Placeholder_61:0\", shape=(None, None), dtype=int64), values=Tensor(\"Placeholder_60:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"Placeholder_59:0\", shape=(None,), dtype=int64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e51508",
   "metadata": {},
   "source": [
    "# Defining Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cfeb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeMinibatchIterator(object):\n",
    "    \"\"\" This minibatch iterator iterates over batches of sampled edges or\n",
    "    random pairs of co-occuring edges.\n",
    "    assoc -- numpy array with target edges\n",
    "    placeholders -- tensorflow placeholders object\n",
    "    batch_size -- size of the minibatches\n",
    "    \"\"\"\n",
    "    def __init__(self, adj_mats, feat, edge_types, batch_size=100, val_test_size=0.01):\n",
    "        self.adj_mats = adj_mats  #Cell 26\n",
    "        self.feat = feat           #{ 0: [12331, 17480 feature matrix], 1: [3215, 16592 feature matrix] }\n",
    "        self.edge_types = edge_types     #{(0, 0): 2, (0, 1): 1, (1, 0): 1, (1, 1): 2}\n",
    "        self.batch_size = batch_size         #512\n",
    "        self.val_test_size = val_test_size       #0.1\n",
    "        self.num_edge_types = sum(self.edge_types.values())        #6\n",
    "\n",
    "        self.iter = 0\n",
    "        self.freebatch_edge_types= list(range(self.num_edge_types))\n",
    "        self.batch_num = [0]*self.num_edge_types        #[0,0,0,0,0,0]\n",
    "        self.current_edge_type_idx = 0      \n",
    "        self.edge_type2idx = {}\n",
    "        self.idx2edge_type = {}\n",
    "        r = 0\n",
    "        for i, j in self.edge_types:\n",
    "            for k in range(self.edge_types[i,j]):\n",
    "                self.edge_type2idx[i, j, k] = r          #{(0,0,0): 0, (0,0,1): 1 ...}\n",
    "                self.idx2edge_type[r] = i, j, k          #{0: (0,0,0), 1: (0,0,1) ...}\n",
    "                r += 1\n",
    "\n",
    "        self.train_edges = {edge_type: [None]*n for edge_type, n in self.edge_types.items()} #{(0,0):[None, None], ..}\n",
    "        self.val_edges = {edge_type: [None]*n for edge_type, n in self.edge_types.items()}\n",
    "        self.test_edges = {edge_type: [None]*n for edge_type, n in self.edge_types.items()}\n",
    "        self.test_edges_false = {edge_type: [None]*n for edge_type, n in self.edge_types.items()}\n",
    "        self.val_edges_false = {edge_type: [None]*n for edge_type, n in self.edge_types.items()}\n",
    "\n",
    "        # Function to build test and val sets with val_test_size positive links\n",
    "        self.adj_train = {edge_type: [None]*n for edge_type, n in self.edge_types.items()} #{(0,0):[None, None], ..}\n",
    "        for i, j in self.edge_types:\n",
    "            for k in range(self.edge_types[i,j]):\n",
    "                self.mask_test_edges((i, j), k)\n",
    "                \n",
    "    def mask_test_edges(self, edge_type, type_idx):\n",
    "        edges_all, _, _ = sparse_to_tuple(self.adj_mats[edge_type][type_idx])  #Cell 26 convert to {(n*2: x,y),n*val,shape} Cell 40\n",
    "        num_test = max(100, int(np.floor(edges_all.shape[0] * self.val_test_size)))  #edges_all are the coords in adj matrix\n",
    "        num_val = max(100, int(np.floor(edges_all.shape[0] * self.val_test_size)))   #num_test is max 100 ??? WHYYYY??\n",
    "\n",
    "        if edge_type not in [(0,1), (1, 0)]:   # DIS_DIS and GENE_GENE only 10 ???? WHYY??\n",
    "            num_test = 10\n",
    "            num_val = 10\n",
    "\n",
    "        all_edge_idx = list(range(edges_all.shape[0]))  #edges_all.shape[0] - > Num of non_zero values in sparse [0,1 .. N]\n",
    "        np.random.shuffle(all_edge_idx)\n",
    "\n",
    "        val_edge_idx = all_edge_idx[:num_val]\n",
    "        val_edges = edges_all[val_edge_idx]\n",
    "\n",
    "        test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "        test_edges = edges_all[test_edge_idx]\n",
    "\n",
    "        train_edges = np.delete(edges_all, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "\n",
    "        #Checks if edges are part of edges_all, then adds to test_edges_false if not there, same length as test_edges\n",
    "        test_edges_false = []\n",
    "        while len(test_edges_false) < len(test_edges):\n",
    "            idx_i = np.random.randint(0, self.adj_mats[edge_type][type_idx].shape[0])\n",
    "            idx_j = np.random.randint(0, self.adj_mats[edge_type][type_idx].shape[1])\n",
    "            if self._ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if test_edges_false:\n",
    "                if self._ismember([idx_i, idx_j], test_edges_false):\n",
    "                    continue\n",
    "            test_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        val_edges_false = []\n",
    "        while len(val_edges_false) < len(val_edges):\n",
    "            idx_i = np.random.randint(0, self.adj_mats[edge_type][type_idx].shape[0])\n",
    "            idx_j = np.random.randint(0, self.adj_mats[edge_type][type_idx].shape[1])\n",
    "            if self._ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if val_edges_false:\n",
    "                if self._ismember([idx_i, idx_j], val_edges_false):\n",
    "                    continue\n",
    "            val_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "        #ALL _edges and _edges_false are arrays of coordinates [n*[x,y]]\n",
    "        # Re-build adj matrices\n",
    "        data = np.ones(train_edges.shape[0])\n",
    "        adj_train = sp.csr_matrix(\n",
    "            (data, (train_edges[:, 0], train_edges[:, 1])), \n",
    "            shape=self.adj_mats[edge_type][type_idx].shape)        #adj_train are now just 1's\n",
    "        self.adj_train[edge_type][type_idx] = self.preprocess_graph(adj_train)\n",
    "\n",
    "        self.train_edges[edge_type][type_idx] = train_edges\n",
    "        self.val_edges[edge_type][type_idx] = val_edges\n",
    "        self.val_edges_false[edge_type][type_idx] = np.array(val_edges_false)\n",
    "        self.test_edges[edge_type][type_idx] = test_edges\n",
    "        self.test_edges_false[edge_type][type_idx] = np.array(test_edges_false)\n",
    "        \n",
    "    def _ismember(self, a, b):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        rows_close = np.all(a - b == 0, axis=1)  #Subtracts the pair a(idx_i, idx_j) from each element of b, if equal then \n",
    "        return np.any(rows_close)                #Function will return true if found a coordinates\n",
    "     \n",
    "    # Symteric (D^-0.5 . (A + I) . D^-0.5) and Assymteric (Dr ^ -0.5 . A . Dc ^ -0.5) normalization\n",
    "    # For A(mxm) -> adj_ = A + I(mxm), R(mx1) = Sum of rows of adj_, M_inv = D(mxm) (diaginals are roots of R), \n",
    "    # Adj_Normalized = (adj(mxm).D(mxm))'.D(mxm)\n",
    "    #For A(mxn) -> R(mx1) = sum of rows of A, C(nx1) = sum of cols of A, RD(mxm) -> Diagonals(non-null) are roots of R,\n",
    "    # CD(nxn) -> Diagonals(non-null) are roots of C  \n",
    "    # Adj_normalized = RD(mxm).A(mxn).CD(nxn) \n",
    "    def preprocess_graph(self, adj):\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        if adj.shape[0] == adj.shape[1]:\n",
    "            adj_ = adj + sp.eye(adj.shape[0])\n",
    "            rowsum = np.array(adj_.sum(1))\n",
    "            degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
    "            adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
    "        else:\n",
    "            rowsum = np.array(adj.sum(1))\n",
    "            colsum = np.array(adj.sum(0))\n",
    "            rowdegree_mat_inv = sp.diags(np.nan_to_num(np.power(rowsum, -0.5)).flatten())\n",
    "            coldegree_mat_inv = sp.diags(np.nan_to_num(np.power(colsum, -0.5)).flatten())\n",
    "            adj_normalized = rowdegree_mat_inv.dot(adj).dot(coldegree_mat_inv).tocoo()\n",
    "        return sparse_to_tuple(adj_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0df506a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12331, 12331)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = [0]*sum(edge_types.values())\n",
    "a,b,c = sparse_to_tuple(adj_mats_orig[(0,0)][0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5388e096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_485307/3169071626.py:120: RuntimeWarning: divide by zero encountered in power\n",
      "  rowdegree_mat_inv = sp.diags(np.nan_to_num(np.power(rowsum, -0.5)).flatten())\n",
      "/tmp/ipykernel_485307/3169071626.py:121: RuntimeWarning: divide by zero encountered in power\n",
      "  coldegree_mat_inv = sp.diags(np.nan_to_num(np.power(colsum, -0.5)).flatten())\n"
     ]
    }
   ],
   "source": [
    "minibatch = EdgeMinibatchIterator(\n",
    "        adj_mats=adj_mats_orig,  #Check cell 26\n",
    "        feat=feat,              #{ 0: [12331, 17480 feature matrix], 1: [3215, 16592 feature matrix] }\n",
    "        edge_types=edge_types,   #{(0, 0): 2, (0, 1): 1, (1, 0): 1, (1, 1): 2}\n",
    "        batch_size=batch_size,      #512\n",
    "        val_test_size=val_test_size  #0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22197b58",
   "metadata": {},
   "source": [
    "##  Defining The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03006503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
    "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010)\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "    initial = tf.compat.v1.random_uniform([input_dim, output_dim], minval=-init_range,\n",
    "                                maxval=init_range, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def weight_variable_xavier(input_dim, output_dim, name=\"\"):\n",
    "    W = tf.get_variable(name, shape=[input_dim, output_dim],\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return W\n",
    "\n",
    "def zeros(input_dim, output_dim, name=None):\n",
    "    \"\"\"All zeros.\"\"\"\n",
    "    initial = tf.zeros((input_dim, output_dim), dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def ones(input_dim, output_dim, name=None):\n",
    "    \"\"\"All zeros.\"\"\"\n",
    "    initial = tf.ones((input_dim, output_dim), dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5907434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global unique layer ID dictionary for layer name assignment\n",
    "_LAYER_UIDS = {}\n",
    "\n",
    "\n",
    "def get_layer_uid(layer_name=''):\n",
    "    \"\"\"Helper function, assigns unique layer IDs\n",
    "    \"\"\"\n",
    "    if layer_name not in _LAYER_UIDS:\n",
    "        _LAYER_UIDS[layer_name] = 1\n",
    "        return 1\n",
    "    else:\n",
    "        _LAYER_UIDS[layer_name] += 1\n",
    "        return _LAYER_UIDS[layer_name]\n",
    "\n",
    "\n",
    "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
    "    \"\"\"Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements) # TODO: CHANGE THIS\n",
    "    \"\"\"\n",
    "    noise_shape = [num_nonzero_elems]\n",
    "    random_tensor = keep_prob         # 1 - dropout\n",
    "    random_tensor += tf.compat.v1.random_uniform(noise_shape)     #Add 1 - dropout to random matrix of Nx1, N is input \n",
    "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)    # If > 1, keep or else drop\n",
    "    pre_out = tf.compat.v1.sparse_retain(x, dropout_mask)\n",
    "    return pre_out * (1./keep_prob)                             # The Remaining elements get multiplied, dropout concept\n",
    "\n",
    "\n",
    "class MultiLayer(object):\n",
    "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
    "\n",
    "    # Properties    \n",
    "        name: String, defines the variable scope of the layer.\n",
    "\n",
    "    # Methods\n",
    "        _call(inputs): Defines computation graph of layer\n",
    "            (i.e. takes input, returns output)\n",
    "        __call__(inputs): Wrapper for _call()\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_type=(), num_types=-1, **kwargs):\n",
    "        self.edge_type = edge_type\n",
    "        self.num_types = num_types\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            layer = self.__class__.__name__.lower()\n",
    "            name = layer + '_' + str(get_layer_uid(layer))\n",
    "        self.name = name\n",
    "        self.vars = {}\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "        self.issparse = False\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        with tf.name_scope(self.name):\n",
    "            outputs = self._call(inputs)\n",
    "            return outputs\n",
    "\n",
    "\n",
    "class GraphConvolutionSparseMulti(MultiLayer):\n",
    "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, adj_mats,\n",
    "                 nonzero_feat, dropout=0., act=tf.nn.relu, **kwargs):\n",
    "        super(GraphConvolutionSparseMulti, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.adj_mats = adj_mats\n",
    "        self.act = act\n",
    "        self.issparse = True\n",
    "        self.nonzero_feat = nonzero_feat\n",
    "        with tf.compat.v1.variable_scope('%s_vars' % self.name):      #weights_i are glorot variables: input_dimxoutput_dim matrix\n",
    "            for k in range(self.num_types):\n",
    "                print(\"Initializing weights: weights_%d with shape: \" %k)\n",
    "                print(str(input_dim[self.edge_type[1]]) + \" \" + str(output_dim))\n",
    "                self.vars['weights_%d' % k] = weight_variable_glorot(\n",
    "                    input_dim[self.edge_type[1]], output_dim, name='weights_%d' % k) #input_dim:  {0: 17480, 1: 16592}\n",
    "                                                                                    #output_dim: hidden_1 units = 64\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        outputs = []\n",
    "        for k in range(self.num_types):\n",
    "            x = dropout_sparse(inputs, 1-self.dropout, self.nonzero_feat[self.edge_type[1]])\n",
    "            x = tf.compat.v1.sparse_tensor_dense_matmul(x, self.vars['weights_%d' % k])\n",
    "            x = tf.compat.v1.sparse_tensor_dense_matmul(self.adj_mats[self.edge_type][k], x)\n",
    "            outputs.append(self.act(x))\n",
    "        outputs = tf.add_n(outputs)\n",
    "        outputs = tf.nn.l2_normalize(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class GraphConvolutionMulti(MultiLayer):\n",
    "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, adj_mats, dropout=0., act=tf.nn.relu, **kwargs):\n",
    "        super(GraphConvolutionMulti, self).__init__(**kwargs)\n",
    "        self.adj_mats = adj_mats\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        with tf.compat.v1.variable_scope('%s_vars' % self.name):\n",
    "            for k in range(self.num_types):\n",
    "                self.vars['weights_%d' % k] = weight_variable_glorot(\n",
    "                    input_dim, output_dim, name='weights_%d' % k)\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        outputs = []\n",
    "        for k in range(self.num_types):\n",
    "            x = tf.nn.dropout(inputs, 1-self.dropout)\n",
    "            x = tf.matmul(x, self.vars['weights_%d' % k])\n",
    "            x = tf.compat.v1.sparse_tensor_dense_matmul(self.adj_mats[self.edge_type][k], x)\n",
    "            outputs.append(self.act(x))\n",
    "        outputs = tf.add_n(outputs)\n",
    "        outputs = tf.nn.l2_normalize(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DEDICOMDecoder(MultiLayer):\n",
    "    \"\"\"DEDICOM Tensor Factorization Decoder model layer for link prediction.\"\"\"\n",
    "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
    "        super(DEDICOMDecoder, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        with tf.variable_scope('%s_vars' % self.name):\n",
    "            self.vars['global_interaction'] = weight_variable_glorot(\n",
    "                input_dim, input_dim, name='global_interaction')\n",
    "            for k in range(self.num_types):\n",
    "                tmp = weight_variable_glorot(\n",
    "                    input_dim, 1, name='local_variation_%d' % k)\n",
    "                self.vars['local_variation_%d' % k] = tf.reshape(tmp, [-1])\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        i, j = self.edge_type\n",
    "        outputs = []\n",
    "        for k in range(self.num_types):\n",
    "            inputs_row = tf.nn.dropout(inputs[i], 1-self.dropout)\n",
    "            inputs_col = tf.nn.dropout(inputs[j], 1-self.dropout)\n",
    "            relation = tf.diag(self.vars['local_variation_%d' % k])\n",
    "            product1 = tf.matmul(inputs_row, relation)\n",
    "            product2 = tf.matmul(product1, self.vars['global_interaction'])\n",
    "            product3 = tf.matmul(product2, relation)\n",
    "            rec = tf.matmul(product3, tf.transpose(inputs_col))\n",
    "            outputs.append(self.act(rec))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class DistMultDecoder(MultiLayer):\n",
    "    \"\"\"DistMult Decoder model layer for link prediction.\"\"\"\n",
    "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
    "        super(DistMultDecoder, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        with tf.variable_scope('%s_vars' % self.name):\n",
    "            for k in range(self.num_types):\n",
    "                tmp = weight_variable_glorot(\n",
    "                    input_dim, 1, name='relation_%d' % k)\n",
    "                self.vars['relation_%d' % k] = tf.reshape(tmp, [-1])\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        i, j = self.edge_type\n",
    "        outputs = []\n",
    "        for k in range(self.num_types):\n",
    "            inputs_row = tf.nn.dropout(inputs[i], 1-self.dropout)\n",
    "            inputs_col = tf.nn.dropout(inputs[j], 1-self.dropout)\n",
    "            relation = tf.diag(self.vars['relation_%d' % k])\n",
    "            intermediate_product = tf.matmul(inputs_row, relation)\n",
    "            rec = tf.matmul(intermediate_product, tf.transpose(inputs_col))\n",
    "            outputs.append(self.act(rec))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BilinearDecoder(MultiLayer):\n",
    "    \"\"\"Bilinear Decoder model layer for link prediction.\"\"\"\n",
    "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
    "        super(BilinearDecoder, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        with tf.variable_scope('%s_vars' % self.name):\n",
    "            for k in range(self.num_types):\n",
    "                self.vars['relation_%d' % k] = weight_variable_glorot(\n",
    "                    input_dim, input_dim, name='relation_%d' % k)\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        i, j = self.edge_type\n",
    "        outputs = []\n",
    "        for k in range(self.num_types):\n",
    "            inputs_row = tf.nn.dropout(inputs[i], 1-self.dropout)\n",
    "            inputs_col = tf.nn.dropout(inputs[j], 1-self.dropout)\n",
    "            intermediate_product = tf.matmul(inputs_row, self.vars['relation_%d' % k])\n",
    "            rec = tf.matmul(intermediate_product, tf.transpose(inputs_col))\n",
    "            outputs.append(self.act(rec))\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class InnerProductDecoder(MultiLayer):\n",
    "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
    "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
    "        super(InnerProductDecoder, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        i, j = self.edge_type\n",
    "        outputs = []\n",
    "        for k in range(self.num_types):\n",
    "            inputs_row = tf.nn.dropout(inputs[i], 1-self.dropout)\n",
    "            inputs_col = tf.nn.dropout(inputs[j], 1-self.dropout)\n",
    "            rec = tf.matmul(inputs_row, tf.transpose(inputs_col))\n",
    "            outputs.append(self.act(rec))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c9e1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            name = self.__class__.__name__.lower()\n",
    "        self.name = name\n",
    "\n",
    "        logging = kwargs.get('logging', True)\n",
    "        self.logging = logging\n",
    "\n",
    "        self.vars = {}\n",
    "\n",
    "    def _build(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\" Wrapper for _build() \"\"\"\n",
    "        with tf.compat.v1.variable_scope(self.name):\n",
    "            self._build()\n",
    "        variables = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "        self.vars = {var.name: var for var in variables}\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class DecagonModel(Model):\n",
    "    def __init__(self, placeholders, num_feat, nonzero_feat, edge_types, decoders, **kwargs):\n",
    "        super(DecagonModel, self).__init__(**kwargs)\n",
    "        self.edge_types = edge_types    #{(0, 0): 2, (0, 1): 1, (1, 0): 1, (1, 1): 2}\n",
    "        self.num_edge_types = sum(self.edge_types.values())      #6\n",
    "        self.num_obj_types = max([i for i, _ in self.edge_types]) + 1       #2\n",
    "        self.decoders = decoders #{(0, 0): 'innerproduct', (0, 1): 'innerproduct', (1, 0): 'innerproduct', (1, 1): 'innerproduct'}    \n",
    "        self.inputs = {i: placeholders['feat_%d' % i] for i, _ in self.edge_types} #sparse tensors with n*indices, n*values, shape\n",
    "        self.input_dim = num_feat  #num_feat:  {0: 17480, 1: 16592}\n",
    "        self.nonzero_feat = nonzero_feat #nonzero_feat:  {0: 12331, 1: 3215}\n",
    "        self.placeholders = placeholders\n",
    "        self.dropout = placeholders['dropout']  #default 0\n",
    "        self.adj_mats = {et: [\n",
    "            placeholders['adj_mats_%d,%d,%d' % (et[0], et[1], k)] for k in range(n)]\n",
    "            for et, n in self.edge_types.items()}\n",
    "        self.build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.hidden1 = defaultdict(list)  #Create empty list when trying to access key not there\n",
    "        for i, j in self.edge_types:\n",
    "            self.hidden1[i].append(GraphConvolutionSparseMulti(\n",
    "                input_dim=self.input_dim, output_dim=hidden1_units,\n",
    "                edge_type=(i,j), num_types=self.edge_types[i,j],         \n",
    "                adj_mats=self.adj_mats, nonzero_feat=self.nonzero_feat,\n",
    "                act=lambda x: x, dropout=self.dropout,       # no activation ??? \n",
    "                logging=self.logging)(self.inputs[j]))      # Logging is only true or false\n",
    "            # self.hidden1[i].append(GraphConvolutionMulti(\n",
    "            #     input_dim=self.input_dim, output_dim=hidden1_units,\n",
    "            #     edge_type=(i,j), num_types=self.edge_types[i,j],\n",
    "            #     adj_mats=self.adj_mats, act=lambda x: x, \n",
    "            #     dropout=self.dropout,logging=self.logging)(self.inputs[j]))\n",
    "\n",
    "        for i, hid1 in self.hidden1.items():\n",
    "            self.hidden1[i] = tf.nn.relu(tf.add_n(hid1))\n",
    "\n",
    "        self.embeddings_reltyp = defaultdict(list)\n",
    "        for i, j in self.edge_types:\n",
    "            self.embeddings_reltyp[i].append(GraphConvolutionMulti(\n",
    "                input_dim=hidden1_units, output_dim=hidden2_units,\n",
    "                edge_type=(i,j), num_types=self.edge_types[i,j],\n",
    "                adj_mats=self.adj_mats, act=lambda x: x,\n",
    "                dropout=self.dropout, logging=self.logging)(self.hidden1[j]))\n",
    "\n",
    "        self.embeddings = [None] * self.num_obj_types\n",
    "        for i, embeds in self.embeddings_reltyp.items():\n",
    "            # self.embeddings[i] = tf.nn.relu(tf.add_n(embeds))\n",
    "            self.embeddings[i] = tf.add_n(embeds)\n",
    "\n",
    "        self.edge_type2decoder = {}\n",
    "        for i, j in self.edge_types:\n",
    "            decoder = self.decoders[i, j]\n",
    "            if decoder == 'innerproduct':\n",
    "                self.edge_type2decoder[i, j] = InnerProductDecoder(\n",
    "                    input_dim=hidden2_units, logging=self.logging,\n",
    "                    edge_type=(i, j), num_types=self.edge_types[i, j],\n",
    "                    act=lambda x: x, dropout=self.dropout)\n",
    "            elif decoder == 'distmult':\n",
    "                self.edge_type2decoder[i, j] = DistMultDecoder(\n",
    "                    input_dim=hidden2_units, logging=self.logging,\n",
    "                    edge_type=(i, j), num_types=self.edge_types[i, j],\n",
    "                    act=lambda x: x, dropout=self.dropout)\n",
    "            elif decoder == 'bilinear':\n",
    "                self.edge_type2decoder[i, j] = BilinearDecoder(\n",
    "                    input_dim=hidden2_units, logging=self.logging,\n",
    "                    edge_type=(i, j), num_types=self.edge_types[i, j],\n",
    "                    act=lambda x: x, dropout=self.dropout)\n",
    "            elif decoder == 'dedicom':\n",
    "                self.edge_type2decoder[i, j] = DEDICOMDecoder(\n",
    "                    input_dim=hidden2_units, logging=self.logging,\n",
    "                    edge_type=(i, j), num_types=self.edge_types[i, j],\n",
    "                    act=lambda x: x, dropout=self.dropout)\n",
    "            else:\n",
    "                raise ValueError('Unknown decoder type')\n",
    "\n",
    "        self.latent_inters = []\n",
    "        self.latent_varies = []\n",
    "        for edge_type in self.edge_types:\n",
    "            decoder = self.decoders[edge_type]\n",
    "            for k in range(self.edge_types[edge_type]):\n",
    "                if decoder == 'innerproduct':\n",
    "                    glb = tf.eye(hidden2_units, hidden2_units)\n",
    "                    loc = tf.eye(hidden2_units, hidden2_units)\n",
    "                elif decoder == 'distmult':\n",
    "                    glb = tf.diag(self.edge_type2decoder[edge_type].vars['relation_%d' % k])\n",
    "                    loc = tf.eye(hidden2_units, hidden2_units)\n",
    "                elif decoder == 'bilinear':\n",
    "                    glb = self.edge_type2decoder[edge_type].vars['relation_%d' % k]\n",
    "                    loc = tf.eye(hidden2_units, hidden2_units)\n",
    "                elif decoder == 'dedicom':\n",
    "                    glb = self.edge_type2decoder[edge_type].vars['global_interaction']\n",
    "                    loc = tf.diag(self.edge_type2decoder[edge_type].vars['local_variation_%d' % k])\n",
    "                else:\n",
    "                    raise ValueError('Unknown decoder type')\n",
    "\n",
    "                self.latent_inters.append(glb)\n",
    "                self.latent_varies.append(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49c6a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "Initializing weights: weights_0 with shape: \n",
      "17480 64\n",
      "Initializing weights: weights_1 with shape: \n",
      "17480 64\n",
      "Args to droput_sparse:  Tensor(\"decagonmodel_14/graphconvolutionsparsemulti_1/sub:0\", shape=(), dtype=float32)   12331\n",
      "Args to droput_sparse:  Tensor(\"decagonmodel_14/graphconvolutionsparsemulti_1/sub_1:0\", shape=(), dtype=float32)   12331\n",
      "Initializing weights: weights_0 with shape: \n",
      "16592 64\n",
      "Args to droput_sparse:  Tensor(\"decagonmodel_14/graphconvolutionsparsemulti_2/sub:0\", shape=(), dtype=float32)   3215\n",
      "Initializing weights: weights_0 with shape: \n",
      "17480 64\n",
      "Args to droput_sparse:  Tensor(\"decagonmodel_14/graphconvolutionsparsemulti_3/sub:0\", shape=(), dtype=float32)   12331\n",
      "Initializing weights: weights_0 with shape: \n",
      "16592 64\n",
      "Initializing weights: weights_1 with shape: \n",
      "16592 64\n",
      "Args to droput_sparse:  Tensor(\"decagonmodel_14/graphconvolutionsparsemulti_4/sub:0\", shape=(), dtype=float32)   3215\n",
      "Args to droput_sparse:  Tensor(\"decagonmodel_14/graphconvolutionsparsemulti_4/sub_1:0\", shape=(), dtype=float32)   3215\n",
      "num_feat:  {0: 17480, 1: 16592}\n",
      "nonzero_feat:  {0: 12331, 1: 3215}\n",
      "edge_types:  {(0, 0): 2, (0, 1): 1, (1, 0): 1, (1, 1): 2}\n",
      "decoders:  {(0, 0): 'innerproduct', (0, 1): 'innerproduct', (1, 0): 'innerproduct', (1, 1): 'innerproduct'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(12331,) dtype=float32>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "        placeholders=placeholders,\n",
    "        num_feat=num_feat,\n",
    "        nonzero_feat=nonzero_feat,\n",
    "        edge_types=edge_types,\n",
    "        decoders=edge_type2decoder,\n",
    ")\n",
    "\n",
    "print(\"num_feat: \", num_feat)\n",
    "print(\"nonzero_feat: \", nonzero_feat)\n",
    "print(\"edge_types: \", edge_types)\n",
    "print(\"decoders: \", edge_type2decoder)  #default 0\n",
    "\n",
    "dropout = tf.compat.v1.placeholder_with_default(0., shape=()),\n",
    "noise_shape = [12331]\n",
    "keep_prob = dropout\n",
    "random_tensor = keep_prob\n",
    "random_tensor += tf.compat.v1.random_uniform(noise_shape)\n",
    "random_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
